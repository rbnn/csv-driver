#!/bin/bash

# `#ifndef NAME/#define NAME'-like header inclusion scheme for bash. This block
# will check, if the given variable is already defined. This normally only
# happens, if the script has alrady been sourced.
if [ -n "${XUTILS_XBASE_SH+x}" ]; then  return 0; fi
declare -ri XUTILS_XBASE_SH=$(date +%s)

# Author:   Ronny Biemann
#           Copyright 2016
# File:     xbase
# License:  GPL-3.0

# NOTICE: Avoid using variable names like `_...'. These are used as local
#         variables within the functions. It might break the script, when using
#         e.g. `_cmd' outside a function, as this is used inside of
#         on_exit_execute_cleanup_stack.
# NOTICE: This script requires to register the EXIT-trap. Therefore you
#         shouldn't overwrite it to not break the script's auto-clean
#         functionality. Nevertheless several functions push their clean-up
#         code into the `cleanup_stack' array, which will be handled on EXIT.
#         If you overwrite the EXIT-trap, YOU are responsible for cleaning up
#         temporary files and stuff. The better solution is to push your
#         clean-up code onto the `cleanup_stack' by
#                           `cleanup_stack+=("YOUR_CODE")'
#         such that the script handles it on exit. The code is executed in
#         reverse order (LIFO) as it is pushed onto the stack.

# Dependencies:
#   bash (required)
#   coreutils (required)
#   grep (required)
#   sed (required)
#   util-linux  (optional)

set -e
trap on_exit_execute_cleanup_stack EXIT # EXIT-signal

# Enable support for bash-builtin script debugging (disable with set +o ... )
# set -o nounset  # Fail on using variables, before they're declared
# set -o verbose  # Echo commands before execution
# set -o xtrace   # Echo commands after command-line processing
# export PS4='$0:$LINENO: '  # Prefix for bash-builtind debug information
# trap 'on_debug "$0" "$LINENO"'  DEBUG # Call on_debug before any command is executed

# ----------------------
# -- Global variables --
# ----------------------
export xbase_fs=${xbase_fs:-,}    # (default) Field separator

# -----------------------------
# -- Configuration variables --
# -----------------------------
export enable_debug=no
# Set `enable_debug_noop=yes' BEFORE sourcing xbase, to bind debug to the no-operation.
export enable_debug_location=yes
export enable_call_stack=yes
export enable_warning=yes
export enable_warning_location=yes
declare -r default_field_separator=,

# Default commands
declare -ar awk_like_programs=("mawk" "awk")
declare -ar cut_like_programs=("cut")
declare -ar egrep_like_programs=("egrep")
declare -ar fgrep_like_programs=("fgrep")
declare -ar getopt_like_programs=("getopt")
declare -ar join_like_programs=("join")
declare -ar nl_like_programs=("nl")
declare -ar parallel_like_programs=("parallel")
declare -ar sed_like_programs=("sed")
declare -ar split_like_programs=("split")
declare -ar sort_like_programs=("sort")

# Array to hold commands, that shall be executed on exit. The code is executed
# in reverse order as they're entered into the array (LIFO).
declare -a cleanup_stack

# Register process ID of top-level shell. This is required to allow the
# die-function to globally abort the current program. Otherwise only the
# sub-shell would be terminated.
# Source: http://stackoverflow.com/a/9894126
declare -r top_level_pid=$$

# ----------------------
# -- Output functions --
# ----------------------

# Change the MODE for debug message generation. Available values for MODE:
#   none      Debug messages are disabled (similar to `enable_debug=no')
#   default   Only print debug messages (see `debug MESSAGE...')
#   verbose   Same as `default' but also print commands as they're read and
#             executed by the shell.
# If MODE is omitted, it defaults to `none'.
#
# Usage: set_debug_mode [MODE]
function set_debug_mode()
{
  #{{{
  case "${1:-none}" in
  default)
    enable_debug=yes
    set +o verbose
    set +o xtrace
    ;;

  verbose)
    enable_debug=yes
    # Print rows as they are read from the scripts
    set -o verbose
    # Print rows as they are executed
    set -o xtrace
    ;;

  none)
    enable_debug=no
    set +o verbose
    set +o xtrace
    ;;

  *) die -1 "Unknown debug-mode: ${1}" ;;
  esac
  #}}}
}

if [ "no" == "${enable_debug_noop:-no}" ]; then
# Write debugging MESSAGE to stderr. The output is controlled by the variables
# enable_debug and enable_debug_location. If enable_debug evaluates to a value
# other than yes, the output of the message is suppressed. Setting
# enable_debug_location to yes adds the current stack location to the output.
#
# Usage: debug MESSAGE...
function debug()
{
  #{{{
  # Skip all execution when debug is off
  [ "yes" != "${enable_debug}" ] && return

  case "${enable_debug_location:-no}" in
  yes) local -r location="$(caller 0 | awk '{print $3":"$1;}'): " ;;
  *) local -r location="" ;;
  esac

  echo "${location}Debug: $@" >&2
  #}}}
}

else
# Alternatively replace debug by the empty function.This will ignore
# enable_debug and suppress all messages given to debug. In debug mode
# `verbose' these lines are read as `debug ...' but will result in `:' (no-op)
# execution.
function debug()
{
  :
}
fi

# Write MESSAGE to stderr. This function is similar to debug. Like debug it is
# controlled by enable_warning and enable_warning_location.
#
# Usage: warning MESSAGE...
function warning()
{
  #{{{
  # Skip all execution when warning is off
  [ "yes" != "${enable_warning}" ] && return

  case "${enable_warning_location:-no}" in
  yes) local -r location="$(caller 0 | awk '{print $3":"$1;}'): " ;;
  *) local -r location="" ;;
  esac

  echo "${location}Warning: $@" >&2
  #}}}
}

# Abort execution with error CODE after printing an error MESSAGE to stderr and
# the content of the call-stack(optionally). The output of the call-stack can
# be enabled by setting `enable_call_stack' to `yes'. This will only be
# ignored, if the column-program from util-linux package isn't installed.
# 
# Usage: die [CODE [MESSAGE...]]
function die()
{
  #{{{
  local -r _ecode=${1:-1}
  shift || true

  # Suppress printing call-stack, if column program (linux-utils) isn't found
  if [ "yes" = "${enable_call_stack:-no}" ]; then
    echo "Call stack:" >&2

    # Print all frame on call-stack to stderr
    local frame=0
    while caller $frame; do ((frame += 1)); done \
      | (printf "frame\tline\tfunction\tfile\n"; nl) \
      | column --table \
      | sed -e 's/^/  /' >&2
  fi

  echo "Error: $@" >&2

  # Source: http://stackoverflow.com/a/9894126
  kill -s TERM ${top_level_pid}
  exit ${_ecode}
  #}}}
}

# Usage: set_fsep [FS]
function set_fsep()
{
  #{{{
  local -r _fs=${1:-${default_field_separator}}
  grep '@' <<< "${_fs}" && die -1 "Field separator must not contain \`@'!"

  # Also update global field separator `xbase_fs'
  xbase_fs="${_fs}"
  echo "${_fs}"
  #}}}
}

# Generate a common help message for configuring the field separator from input
# ARG. This is generally done by the flag `-t ARG'
#
# Usage: fsep_help_message [ARG]
function fsep_help_message()
{
  echo "Use ${1:-FS} instead of COMMA for field delimiter"
}

# Generate a common help message for the flags to request help. Generally these
# are -h or --help.
#
# Usage: help_help_message
function help_help_message()
{
  echo "Print this message and terminate"
}

# Usage: getopt_help_message PROGRAM BACKEND VARIABLE [DEFAULT_FLAGS]
function getopt_help_message()
{
  #{{{
  local -r program=${1:?Missing PROGRAM}
  local -r backend=${2:?Missing BACKEND}
  local -r variable=${3:?Missing VARIABLE}
  local -r getopt=$(find_program_like ${getopt_like_programs})

  cat << EOF
As ${program} is a frontend to ${backend}, two methods
are implemented to pass extra options to the underlying backend:
1.  ${getopt} is used to parse commandline options. It stops parsing options on
    \`--' and takes all input thereafter as non-option arguments. These
    non-option arguments are passed directly to the backend
2.  By defining the environment variable \`${variable}' options can be passed
    to the backend (default is \`${4}').
EOF
  #}}}
}

# ----------------------------------------
# -- Functions working with header data --
# ----------------------------------------

# Join elements of ARRAY into a single line. Subsequent elements will be
# separated by FS.
#
# Usage: join_by [ARRAY [FS]]
function join_by()
{
  #{{{
  join_by_str "${1}" "${2:-}"
  # # Read header names as first argument
  # local -ra _array=(${!1})

  # # Read (optional) field-separator
  # # Default field-separator is comma `,'
  # local IFS=${2:-${xbase_fs}}
  # echo "${_array[*]}"
  #}}}
}

# Deprecated: `join_by(_str)?' are equivalent
# Join elements of ARRAY into a single line. Subsequent elements will be
# separated by FS. FS may contain multiple characters.
#
# Usage: join_by_str [ARRAY [FS]]
function join_by_str()
{
  #{{{
  local -ra _array=(${!1})
  local -r _fs=${2-${xbase_fs}}

  local -i _n=${#_array[@]}
  local _str=""

  if (( 0 < $_n )); then
    _str=$(printf -- "%s" "${_array[0]}")
    (( 1 < $_n )) && _str+=$(printf -- "${_fs}%s" "${_array[@]:1}")
  fi

  echo "${_str}"
  #}}}
}

# Usage: read_header FD FS [PREFIX]
function read_header()
{
  #{{{
  local -r _fd=${1:?Missing FD}
  local -r _fs=${2:?Missing FS}
  local -r _prefix=${3}

  # Read from FD without interpreting escape sequences. Wrapping with eval is
  # required, to re-parse the redirection. As redirection is handled prior to
  # variable substitution.
  eval "IFS= read -r _raw_header <&${_fd}"

  # Like always, parse the header string
  parse_header "${_raw_header}" "${_fs}" "${_prefix}"

  # Return the raw-header into variable <PREFIX>raw_header.
  eval "${_prefix}raw_header"='"${_raw_header}"'
  #}}}
}

# Parse column names from STR. Therefore STR must be a single line and it is
# split on FS and the column names are saved in the array <PREFIX>fields. PREFIX
# is an optional argument and default to an empty string.
#
# Usage: parse_header STR FS [PREFIX]
function parse_header()
{
  #{{{
  local -a fields
  # local -a columns

  local IFS=${2:?Missing FS}
  read -r -a fields <<< "${1:?Missing STR}"

  # Check for non-empty column names
  local -i no=1
  for fn in "${fields[@]}"; do
    [ -z "${fn}" ] && die -1 "Field name ${no} must not be empty!"
    ((no + 1))
  done

  # Export arrays with prefix as global variables
  eval "${3}fields"='("${fields[@]}")'
  #}}}
}

# Locate fields within ARRAY by their column name. A field specifier may
# additionally contain sort(1) flags. These flags are appended to the column
# name, thus FIELD is `NAME[:FLAGS]'. According to the manpage of sort(1),
# amongst others FLAGS may contain `g' for sorting by generic numbers. The
# function will define the arrays <PREFIX>index, <PREFIX>flags and
# <PREFIX>found. The first two arrays store the column number and sort flags of
# the FIELDs by their order passed to the function. The third array contains
# the column names of the FIELDs sorted by their column number. The function
# will fail with an error message if at least one FIELD could not be found in
# the header.
#
# Usage: locate_fields ARRAY PREFIX FIELD...
function locate_fields()
{
  #{{{
  # Read header names and prefix
  local -ra _array=(${!1:?Missing ARRAY})
  local -r _prefix=${2:?Missing PREFIX}
  shift 2

  local -a _index
  local -a _flags

  for _fn in "$@"; do

    local -i _fn_idx=-1
    local -i _hn_idx=0

    # Strip sort flags from field name
    [ -z "${_fn}" ] && die -1 "Empty field name!"
    _N=${_fn%%:*}

    # Keep suffix from field name, i.e. from next character on after `:'
    _O=${_fn:$((${#_N} + 1))}

    # Search for _N in column names
    for _hn in "${_array[@]}"; do
      if [ "${_hn}" == "${_N}" ]; then
        _fn_idx=${_hn_idx}
        break
      fi

      _hn_idx=$((_hn_idx + 1))
    done

    # Raise error, if field could not be found
    (( 0 > ${_fn_idx} )) && die -1 "No such field: ${_N}"

    _index+=("${_fn_idx}")
    _flags+=("${_O}")
  done

  # Sort selected fields by column-number
  local -ra _sorted=($(printf "%s\n" "${_index[@]}" | sort -n))
  local -a _found

  for _idx in "${_sorted[@]}"; do
    _found+=("${_array[${_idx}]}")
  done

  # Export arrays with prefix as global variables
  eval "${_prefix}index"='("${_index[@]}")'
  eval "${_prefix}found"='("${_found[@]}")'
  eval "${_prefix}flags"='("${_flags[@]}")'
  #}}}
}

# This function returns the arrays <PREFIX>index, <PREFIX>flags and
# <PREFIX>found for all available fields. This has the same effect as it would,
# when passing all available fields to the locate_fields-function. The sort(1)
# FLAGS are applied to all fields (default is `g').
#
# Usage: select_all_fields ARRAY PREFIX [FLAGS]
function select_all_fields()
{
  #{{{
  local -ra _array=(${!1:?Missing ARRAY})
  local -r _prefix=${2?Missing PREFIX}
  local -r _default_flags=${3:-g} # Default sort flags

  local -a _index
  local -a _flags
  local -a _found

  for _fn in "${_array[@]}"; do
    _index+=("${#_index[@]}")
    _flags+=("${_default_flags}")
    _found+=("${_fn}")
  done

  # Export arrays with prefix as global variables
  eval "${_prefix}index"='("${_index[@]}")'
  eval "${_prefix}found"='("${_found[@]}")'
  eval "${_prefix}flags"='("${_flags[@]}")'
  #}}}
}

# This functions returns the array <PREFIX>index by selecting unique column
# names from ARRAY. The first occurrence of each column name is taken as
# unique.
#
# Usage: select_unique_fields ARRAY PREFIX
function select_unique_fields()
{
  #{{{
  local -ra _array=(${!1:?Missing ARRAY})
  local -ri _n_col=${#_array[@]}
  local -r _prefix=${2?Missing PREFIX}

  local -a _unique_fields
  local -a _index
  local -i _fno=0
  local _found

  # Iterate all given field names and add them to `_unique_fields' iff they're
  # not already contained. Also store their index and return it as result.
  for _fn in "${_array[@]}"; do
    _found=no

    for _ufn in "${_unique_fields[@]}"; do
      # Check if `_fn' (field-name) has already been added to the
      # `_unique_fields' and stop current inner loop if so. We don't need to
      # count the duplicates.
      if [ "${_fn}" == "${_ufn}" ]; then
        debug "Found duplicate field: ${_fn}"
        _found=yes
        break
      fi
    done

    if [ "yes" != "${_found}" ]; then
      _unique_fields+=("${_fn}")
      _index+=(${_fno})
    fi

    ((_fno += 1))
  done

  # Export arrays with prefix as global variables
  eval "${_prefix}index"='("${_index[@]}")'
  #}}}
}

# Prepend STR to all elements of ARRAY. The result will be stored in
# <PREFIX>fields. PREFIX is an optional argument and defaults to an empty
# string.
#
# Usage: add_prefix_to_fields ARRAY STR [PREFIX] 
function add_prefix_to_fields()
{
  #{{{
  local -ra _array=(${!1:?Missing ARRAY})
  local -r _str=${2:?Missing STR}

  local -a _fields
  for _fn in ${_array[@]}; do
    _fields+=("${_str}${_fn}")
  done

  # Export arrays with prefix as global variables
  eval "${3}fields"='("${_fields[@]}")'
  #}}}
}

# Append STR to all elements of ARRAY. The result will be stored in
# <PREFIX>fields. PREFIX is an optional argument and defaults to an empty
# string.
#
# Usage: add_suffix_to_fields ARRAY STR [PREFIX] 
function add_suffix_to_fields()
{
  #{{{
  local -ra _array=(${!1:?Missing ARRAY})
  local -r _str=${2:?Missing STR}

  local -a _fields
  for _fn in ${_array[@]}; do
    _fields+=("${_fn}${_str}")
  done

  # Export arrays with prefix as global variables
  eval "${3}fields"='("${_fields[@]}")'
  #}}}
}

# Delete elements pointed to by INDEX from ARRAY. The result will be stored in
# <PREFIX>fields. PREFIX is an optional argument and defaults to an empty
# string.
#
# Usage: delete_fields_by_index ARRAY INDEX [PREFIX]
function delete_fields_by_index()
{
  #{{{
  local -ra _array=(${!1:?Missing ARRAY})
  local -ra _select=(${!2:?Missing INDEX})

  local -a _fields
  local -i _idx=0

  for _fn in ${_array[@]}; do
    _found=no

    for _jdx in ${_select[@]}; do
      if (( ${_idx} == ${_jdx} )); then
        _found=yes
        break
      fi
    done

    # Only keep column, that wasn't found in selection
    [ "yes" != "${_found}" ] && _fields+=("${_fn}")

    ((_idx += 1))
  done

  # Export arrays with prefix as global variables
  eval "${3}fields"='("${_fields[@]}")'
  #}}}
}

# Usage: match_fields_by_pattern ARRAY PATTERN [PREFIX]
function match_fields_by_pattern()
{
  #{{{
  local -ra _array=(${!1:?Missing ARRAY})
  local -r _pattern=${2:?Missing PATTERN}

  local -a _like
  local -a _unlike
  local -i _idx=0

  for _fn in "${_array[@]}"; do
    # Split input fields into two distinct sets:
    # 1. `_like'    Fields that match the given PATTERN
    # 2. `_unlike'  Fields than don't match the PATTERN
    if egrep "${_pattern}" <<< "${_fn}" > /dev/null; then
      _like+=("${_fn}")
    else
      _unlike+=("${_fn}")
    fi
  done

  # Export remaining fields
  eval "${3}fields_like"='("${_like[@]}")'
  eval "${3}fields_unlike"='("${_unlike[@]}")'
  #}}}
}

# --------------------
# -- File functions --
# --------------------

# Connect files FILE_1 to FILE_N to fifos 1 to N. The full path to the fifos is
# written into the array PREFIX_fifos. This function internally calls the
# xcat-tool for every input file and generates background jobs to automatically
# decompress the contents. It is also possible to pass the special file `-'
# (a.k.a. stdin) at most once, to handle data from standard input. To handle
# all the fifos, the function creates a new temporary directory and poluplates
# it with the fifos. All temporary files and directories are added pushed onto
# cleanup_stack to be removed by the on_exit_execute_cleanup_stack handler.
#
# Usage: connect_files PREFIX FILE_1 [... FILE_N]
function connect_files()
{
  #{{{
  local -r prefix=${1}
  shift || die -1 "Missing PREFIX!"
  [ 0 -lt $# ] || die -1 "Missing FILE_1!"

  local -r tmpdir=$(mktemp -d)
  cleanup_stack+=("rmdir '${tmpdir}'")
  debug "Populating temporary directory \`${tmpdir}'..."

  # Open all input files and pass them to the xcat-tool to transparently
  # decompress them if needed. This also allows to handle the special `-' file
  # (a.k.a. stdin).
  local used_stdin_file=no
  local -a files
  for fn in "$@"; do
    idx=${#files[@]}
    fifo=$(printf "%s/%03i" "${tmpdir}" ${idx})
    mkfifo "${fifo}" || die -1 "Cannot create fifo \`${fifo}'!"
    cleanup_stack+=("rm '${fifo}'")
    files+=("${fifo}")

    # Check for multiple use of stdin
    if [ "-" == "${fn}" ]; then
      [ "no" != "${used_stdin_file}" ] && die -1 "Multiple use of \`-'!"
      used_stdin_file=yes
    fi

    debug "Connecting input file \`${fn}' to fifo \`${fifo}'..."
    if [ "-" != "${fn}" ]; then
      xcat "${fn}" > "${fifo}" &
    else 
      cat <&0 > "${fifo}" &
    fi

  done

  # Export arrays with prefix as global variables
  eval "${prefix}fifos"='("${files[@]}")'
  #}}}
}

# Return the next unused file descriptor. The function checks the
# /proc/<PID>/fd/ directory and tries to find the minimum of I such that I is
# no file in this directory. According the the specification of the
# proc-filesystem, this directory contains all open file-descriptors for the
# given process-ID.
#
# Usage: next_fd
function next_fd()
{
  #{{{
  # Source: http://stackoverflow.com/a/8342705
  local fd=3

  while [ -e "/proc/$$/fd/${fd}" ]; do
    debug "File descriptor ${fd} already in use."
    fd=$((fd + 1))
  done

  debug "Found unused file descriptor: ${fd}"
  echo "${fd}"
  #}}}
}

# Open files FILE_1 to FILE_N and return the corresponding file descriptors.
# The file descriptors are written into the array PREFIX_fds. The files have to
# be closed manually or by calling close_files.
#
# Usage: open_files PREFIX FILE1 [... FILEN]
function open_files()
{
  #{{{
  local -r prefix=${1}
  shift || die -1 "Missing PREFIX!"
  [ 0 -lt $# ] || die -1 "Missing FILE1!"

  local -a fds
  for fn in "$@"; do
    local fd=$(next_fd)
    debug "Open file \`${fn}'(${fd})..."

    # Open file descriptors read only
    eval "exec ${fd}<'${fn}'" || die -1 "Cannot open \`${fn}' with fd ${fd}!"
    fds+=("${fd}")
  done

  # Export arrays with prefix as global variables
  eval "${prefix}fds"='("${fds[@]}")'
  #}}}
}

# Close file descriptors FD1 to FDN.
#
# Usage: close_files [FD1 [... FDN]]
function close_files()
{
  #{{{
  for fd in "$@"; do
    debug "Close file descriptor ${fd}."
    eval "exec ${fd}<&-"
  done
  #}}}
}

# ---------------------
# -- Other functions --
# ---------------------

# Find any program from the given LIST. The idea is to specify a list of
# similar programs and allow any of them to fullfill the requirement. The
# function will return the path to the first element that is found by the order
# of the LIST. If no program is found, the function will die with an error
# message.
#
# Usage: find_program_like LIST...
function find_program_like()
{
  #{{{
  for pn in "$@"; do
    path=$(which ${pn} 2> /dev/null)

    if [ -x "${path}" ]; then
      echo "${path}"
      return
    fi
  done

  die -1 "Could not find any of: $@"
  #}}}
}

# Generate a temporary direktory and add a corresponding entry to the
# cleanup_stack.
#
# Usage: make_tempdir
function make_tempdir()
{
  #{{{
  local -r tmpdir=$(mktemp -d)
  debug "Create temporary directory: ${tmpdir}"
  echo "${tmpdir}"
  #}}}
}

# Usage: pretty_table FS
function pretty_table()
{
  #{{{
  local -r fsep=${1:?Missing FS}

  local -r column_bin=$(which column 2> /dev/null)

  if [ ! -x "${column_bin}" ]; then cat -
  else ${column_bin} --table --separator=${fsep} <&0
  fi
  #}}}
}

# Execute stack for clean-up process. The stack is executed in REVERSED order.
# I.e. the last element is executed first, and so on.
#
# Usage: execute_cleanup_stack STACK
function execute_cleanup_stack()
{
  #{{{
  local -ra _stack=("${!1-}")

  for((i = 1; i <= ${#_stack[@]}; i += 1)); do
    local _cmd="${_stack[$((-i))]}"

    [ -z "${_cmd}" ] && continue

    debug "Clean-up: ${_cmd}"
    eval ${_cmd} || warning "Clean-up failed: ${_cmd}"
  done
  #}}}
}

# Action handler for EXT-trap.
function on_exit_execute_cleanup_stack()
{
  #{{{
  debug "Preparing for clean exit..."
  execute_cleanup_stack cleanup_stack[@]
  debug "Done."
  #}}}
}
